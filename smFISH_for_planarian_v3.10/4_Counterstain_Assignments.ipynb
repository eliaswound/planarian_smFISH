{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c17c9ed-180c-4ec6-ae94-7e4cc0d56b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterstainAssignment = False\n",
    "controlImage = True\n",
    "counterstainControlPath = None\n",
    "smFISHChannelPath = \"/Users/eliasguan/Desktop/306_analysis_results/Experiment/6hr_Amputation/Image1/565/6hr_Amputation_Image1_565.tif\"\n",
    "counterstainChannelPath = None\n",
    "nucleiSegmentationPath = \"/Users/eliasguan/Desktop/306_analysis_results/Experiment/6hr_Incision/Image1/565/results/labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83421ae3-d57b-4af0-b7ea-853a59d1863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpotLabel = False \n",
    "labelExpansionSize = 20\n",
    "nuclei_projection_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6a7de5-cf39-4c70-b715-5e20ec29bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is for importing all the functions for smFISH detection. Please install them if you dont have these pacakges. \n",
    "import os\n",
    "import sys\n",
    "# import tk for getting the directory faster. dont need this in a command line/server version\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import bigfish.detection \n",
    "import bigfish.stack\n",
    "import bigfish.plot\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "# if you dont need to plot in jupyter you don need these. Some magic interperters need to be removed for command line version. \n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Glob and tifffile are needed\n",
    "from glob import glob\n",
    "from tifffile import imread,imwrite\n",
    "# csb deep is to take normalization \n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "# This is your stardist models and everything in stardist coming from. \n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "from skimage import segmentation\n",
    "import bigfish.multistack as multistack\n",
    "# Set random seed for you color map. You do not really need this to be 6 all the time, but its okay. \n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51238c8-81f0-48f2-8abb-838143ef18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_file(filename):\n",
    "    try:\n",
    "        data = np.load(filename)\n",
    "        print(f\"Loaded {filename} successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{filename} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "    return None\n",
    "def make_stardist_Predictions_labels (dataset, normalized = False, normalize_low = 0, normalize_high = 0, nms_thresh = 0, prob_thresh = 0): \n",
    "    ''' input: csbdeep input: If this image is a csbdeep filtered image. If this is true, the image will not be normalized. \n",
    "               dataset: The data set you want to analysis on \n",
    "               normalize_low and normalized_high: The parameter you want to normalize, if either of them is 0 will use default value (1,99.8)\n",
    "               if not then will use these values \n",
    "               nms_thresh and prob_thrsh : the parameter of overlapping and probablity threshold. If eitehr of them is 0 will use default value \n",
    "               for the model (depend on the model) if not then use these values\n",
    "    '''\n",
    "    labels_collection= []\n",
    "    for i in range(len(dataset)): \n",
    "        if not normalized:\n",
    "            if normalize_low ==0 or normalize_high == 0:\n",
    "                img = normalize(dataset[i], 1,99.8, axis=(0,1))\n",
    "            else:\n",
    "                img = normalize(dataset[i], normalize_low, normalize_high, axis=(0,1))\n",
    "        else:\n",
    "            img = dataset[i]\n",
    "        if nms_thresh == 0 or prob_thresh == 0 :\n",
    "            labels, details = model.predict_instances(img)\n",
    "        else: \n",
    "            labels, details = model.predict_instances(img,nms_thresh = nms_thresh, prob_thresh = prob_thresh)\n",
    "        # write labels\n",
    "        labels_collection.append(labels)\n",
    "        export_imagej_rois('polygons/polygon_rois_'+str(i).zfill(3)+'.zip', details['coord'])\n",
    "        imwrite(\"labels/Nucleus_Labels_\"+str(i).zfill(3)+\".tif\", labels)\n",
    "    labels_collection = np.array(labels_collection, dtype = np.uint16)\n",
    "    return labels_collection\n",
    "def random_select_images(dataset, percentage):\n",
    "    \"\"\"\n",
    "    Randomly select a certain percentage of images from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (list): A list containing 2D arrays (images).\n",
    "        percentage (float): Percentage of images to be selected.\n",
    "\n",
    "    Returns:\n",
    "        selected_indices (list): A list of indices corresponding to the selected images.\n",
    "    \"\"\"\n",
    "    num_images = len(dataset)\n",
    "    num_selected = int(np.ceil(percentage/100 * num_images))\n",
    "    selected_indices = np.random.choice(num_images, num_selected, replace=False)\n",
    "    return selected_indices\n",
    "\n",
    "def random_select_region(image, region_size):\n",
    "    \"\"\"\n",
    "    Randomly select a region within the image with a certain size.\n",
    "\n",
    "    Parameters:\n",
    "        image (2D array): The original image.\n",
    "        region_size (tuple): The size of the region to be selected (height, width).\n",
    "\n",
    "    Returns:\n",
    "        region (2D array): The selected region.\n",
    "    \"\"\"\n",
    "    image_height, image_width = image.shape\n",
    "    region_height, region_width = region_size\n",
    "\n",
    "    if region_height > image_height or region_width > image_width:\n",
    "        raise ValueError(\"Region size exceeds original image size.\")\n",
    "\n",
    "    start_row = np.random.randint(0, image_height - region_height + 1)\n",
    "    start_col = np.random.randint(0, image_width - region_width + 1)\n",
    "    end_row = start_row + region_height\n",
    "    end_col = start_col + region_width\n",
    "\n",
    "    region_prop = [(start_row, end_row),(start_col,end_col)]\n",
    "    return region_prop\n",
    "def make_random_examples(dataset, normalize_low = 0, normalize_high =0, nms_thresh =0, prob_thresh = 0, normalized = False, percentage = 20, region_size = (500,500)):\n",
    "    selected_indicies = sorted(random_select_images(dataset, percentage))\n",
    "    for item in selected_indicies: \n",
    "        if normalized:\n",
    "            img = dataset[item]\n",
    "        else:\n",
    "            if normalize_low ==0 or normalize_high == 0:\n",
    "                img = normalize(dataset[item], 1,99.8, axis=(0,1))\n",
    "            else:\n",
    "                img = normalize(dataset[item], normalize_low, normalize_high, axis=(0,1))   \n",
    "        if nms_thresh == 0 or prob_thresh == 0 :\n",
    "            labels, details = model.predict_instances(img)\n",
    "        else: \n",
    "            labels, details = model.predict_instances(img, nms_thresh = nms_thresh, prob_thresh = prob_thresh)\n",
    "        region_props =  random_select_region(img, region_size)\n",
    "        cropped_image = img[region_props[0][0]:region_props[0][1],region_props[1][0]:region_props[1][1]]\n",
    "        cropped_label = labels[region_props[0][0]:region_props[0][1],region_props[1][0]:region_props[1][1]]\n",
    "        figure = plt.figure(figsize=(13,10))\n",
    "        coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "        # Plot image on the first one\n",
    "        ax1 = figure.add_subplot(121); ax1.imshow(cropped_image, cmap='gray'); ax1.axis('off')\n",
    "        # Plot image on the second one\n",
    "        ax2 = figure.add_subplot(122); ax2.imshow(cropped_image, cmap='gray'); ax2.axis('off')\n",
    "        # Plot labels on the third one. \n",
    "        ax2.imshow(cropped_label, cmap=lbl_cmap, alpha=0.3)\n",
    "        figure.tight_layout()\n",
    "        plt.savefig(\"random_examples/random_example_\"+str(item).zfill(3)+\".tif\")\n",
    "def create_folder_in_same_directory(file_path, folder_name):\n",
    "    \"\"\"\n",
    "    Creates a folder with the specified name in the same directory as the given file.\n",
    "    If the folder already exists, it returns the existing path.\n",
    "    \"\"\"\n",
    "    # Get the directory of the given file\n",
    "    directory = os.path.dirname(file_path)\n",
    "    \n",
    "    # Define the path for the specified folder\n",
    "    folder_path = os.path.join(directory, folder_name)\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created '{folder_name}' folder at: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"'{folder_name}' folder already exists at: {folder_path}\")\n",
    "    \n",
    "    return folder_path\n",
    "def generate_max_projection_array(array, projection_size):\n",
    "    ranges = []\n",
    "    total = array.shape[0]\n",
    "    projected_image = []\n",
    "    for i in range(0, total, projection_size):\n",
    "        start = i\n",
    "        end = min(i + projection_size - 1, total - 1)\n",
    "        ranges.append((start, end))\n",
    "    for item in ranges:\n",
    "        start, end = item\n",
    "\n",
    "        for i in range(start,end):\n",
    "            nuclei_array.append(array[i])\n",
    "        projection = bigfish.stack.maximum_projection(np.array(nuclei_array,dtype=np.uint8))\n",
    "        projected_image.append(projection)\n",
    "    return np.array(projected_image,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0903936-8d4e-4ad1-8723-b81968d88212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into your counterstain spots\n",
    "if counterstainAssignment:\n",
    "    os.chdir(os.path.dirname(counterstainChannelPath))\n",
    "    os.chdir(\"results\")\n",
    "    # Read in your counterstain spots file \n",
    "    # File names\n",
    "    file_A = 'spots_post_decomposition_and_background_removed.npy'\n",
    "    file_B = 'spots_post_decomposition.npy'\n",
    "\n",
    "    # Try loading A, fallback to B if A fails\n",
    "    post_decomposition_array = load_npy_file(file_A)\n",
    "    if post_decomposition_array is None:\n",
    "        post_decomposition_array = load_npy_file(file_B)\n",
    "    post_decomposition_array_projected = np.copy(post_decomposition_array)  # Create a copy of the original array\n",
    "    post_decomposition_array_projected[:, 0] = np.floor_divide(post_decomposition_array[:, 0], nuclei_projection_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ea5894-840e-4524-975e-060ea09d6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(nucleiSegmentationPath)\n",
    "nucleiFileNames = sorted(glob(\"*.tif\"))\n",
    "nucleiImageArray_projected_labels = []\n",
    "for item in nucleiFileNames:\n",
    "    nucleiImage = imread(item)\n",
    "    nucleiImageArray_projected_labels.append(nucleiImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73613527-9466-4ac8-bb03-baca9f2be46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'expanded_labels' folder at: expanded_labels\n",
      "Created 'assignment_maps' folder at: assignment_maps\n"
     ]
    }
   ],
   "source": [
    "if counterstainAssignment:\n",
    "    os.chdir(os.path.dirname(counterstainChannelPath))\n",
    "    os.chdir(\"results\")\n",
    "    create_folder_in_same_directory(\".\", \"expanded_labels\")\n",
    "    create_folder_in_same_directory(\".\", \"counterstain_labels\")\n",
    "    create_folder_in_same_directory(\".\", \"counterstain_assignment_maps\")\n",
    "    spot_in_background = []\n",
    "    counterstain_assignment_results = []\n",
    "else:\n",
    "    os.chdir(os.path.dirname(smFISHChannelPath))\n",
    "    os.chdir(\"results\")\n",
    "    create_folder_in_same_directory(\".\", \"expanded_labels\")\n",
    "    create_folder_in_same_directory(\".\", \"assignment_maps\")\n",
    "for i in range(len(nucleiImageArray_projected_labels)):\n",
    "    # Expanding labels \n",
    "    expanded_labels = segmentation.expand_labels(nucleiImageArray_projected_labels[i], distance=labelExpansionSize)\n",
    "    # Find your spots belong to this projection \n",
    "    if counterstainAssignment:\n",
    "        indices = np.where(post_decomposition_array_projected[:, 0] == i)[0]\n",
    "        # Remove the z-stack information from your RNA detection\n",
    "        rna_coord = post_decomposition_array_projected[indices][:, -2:]\n",
    "        # Data type configureation. Changing dtype will probablly \n",
    "        # Get you more compatible with bigfish also makes calculation easier\n",
    "        rna_coord = rna_coord.astype(dtype=\"int64\")\n",
    "        cell_RNACount = np.zeros(np.max(expanded_labels)+1)\n",
    "    expanded_labels = expanded_labels.astype(dtype=np.uint16)\n",
    "    \n",
    "    # Save your expanded labels \n",
    "    imwrite('expanded_labels/20expandedlabel'+str(i).zfill(3)+'.tif', expanded_labels, photometric = 'minisblack')\n",
    "    # Get cell RNA counter as a zero array \n",
    "    if counterstainAssignment:\n",
    "        # Iterate through your RNA coordinates \n",
    "        for item in rna_coord:\n",
    "            # Find the value of this RNA center spot\n",
    "            location = expanded_labels[item[0],item[1]]\n",
    "            # Add on to your RNA counter\n",
    "            cell_RNACount[location] = cell_RNACount[location]+1\n",
    "        # Add your results to your collection\n",
    "        counterstain_assignment_results.append(cell_RNACount[1:])\n",
    "        # Create empty assignment maps \n",
    "        assignment_map = np.zeros(expanded_labels.shape, dtype = np.uint8)\n",
    "        assignment_label = np.zeros(expanded_labels.shape, dtype = np.uint64)\n",
    "        # Create your maps \n",
    "        k = 1\n",
    "        for j in tqdm(range(1,len(cell_RNACount))):\n",
    "            indices = np.where(expanded_labels == j)\n",
    "            assignment_map[indices] = cell_RNACount[j]\n",
    "            if cell_RNACount[j] != 0 :\n",
    "                assignment_label[indices] = k\n",
    "                k = k+1\n",
    "            else:\n",
    "                assignment_label[indices] = 0\n",
    "        spot_in_background.append(cell_RNACount[0])\n",
    "        imwrite('counterstain_labels/assignment_map'+str(i).zfill(3)+'.tif', assignment_label, photometric = 'minisblack')\n",
    "        imwrite('counterstain_assignment_maps/assignment_map'+str(i).zfill(3)+'.tif', assignment_map, photometric = 'minisblack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8340999-0c81-4665-80db-db1a3f61ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if counterstainAssignment:\n",
    "    np.savez(\"counterstain_assignment_result.npz\", *counterstain_assignment_results)\n",
    "    np.save(\"counterstain_spot_in_background.npy\", spot_in_background)\n",
    "    np.save(\"concatenated_spot_counterstain.npy\", np.concatenate(counterstain_assignment_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f30971-f136-493a-bbd2-da74302b0859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stardist-env",
   "language": "python",
   "name": "stardist-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
